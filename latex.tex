% !TEX root = ./main.tex

\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{float}
\usepackage{hyperref}

\geometry{margin=1in}

\title{Machine Learning Project Report\\
\large Phishing Website Detection Using Classical and Ensemble Models}
\author{Group Members}
\date{}

\begin{document}
\maketitle

\section{Business Scope}
Phishing attacks are one of the most widespread cybersecurity threats, using deceptive websites to steal personal and financial data.  
The objective of this project is to build a machine learning system capable of distinguishing between legitimate and phishing websites using structured features extracted from URLs, domain metadata, and webpage behavior indicators.

This problem is highly relevant to the cybersecurity domain. Organisations increasingly rely on automated tools to detect malicious websites at scale.  
Our model aims to support such detection by classifying websites based on engineered features rather than raw textual URL content.

\section{Problem Formalisation and Methods}
The task is formulated as a \textbf{binary supervised classification problem}:  
\begin{itemize}
    \item Class 0: legitimate website  
    \item Class 1: phishing website
\end{itemize}

We use a labelled dataset from the UCI Machine Learning Repository containing 11,055 samples and 30 engineered features.  
The methods explored include:
\begin{itemize}
    \item Classical ML models (Logistic Regression, SVM, KNN, Decision Tree)
    \item Ensemble models (Random Forest, Gradient Boosting)
    \item Outlier detection using Isolation Forest
\end{itemize}

\section{Data Description and Exploration}
The dataset consists of 30 discrete features taking values in $\{-1, 0, 1\}$, representing URL and website characteristics such as:
\begin{itemize}
    \item presence of IP address in URL,
    \item SSL certificate validity,
    \item number of subdomains,
    \item page ranking,
    \item link and anchor behaviours.
\end{itemize}

\subsection{Dataset Size}
\begin{itemize}
    \item Features: 11,055 rows $\times$ 30 columns
    \item Class distribution: 44.3\% phishing, 55.7\% legitimate
\end{itemize}

\subsection{Missing Values}
No missing values were found:
\begin{quote}
\texttt{Missing Values: 0}
\end{quote}

\subsection{Duplicate Analysis}
A detailed duplicate analysis showed:
\begin{itemize}
    \item 70.9\% complete duplicates
    \item 71.3\% feature duplicates
    \item 64 conflicting feature groups (3.2\% of samples)
\end{itemize}

These high duplicate rates are expected because the dataset uses discrete engineered features with limited variation.  
Phishing pages often exhibit repeated patterns, explaining the repetition.

\subsection{Imbalanced Data}
Class ratio:
\begin{quote}
\texttt{Legitimate: 55.7\%, Phishing: 44.3\%}
\end{quote}
The dataset is nearly balanced. No resampling was required.

\subsection{Outlier Analysis}
Using Isolation Forest (contamination = 0.05), we detected:
\begin{itemize}
    \item 553 outliers (5\%)
    \item More phishing outliers (7.2\%) than legitimate (3.2\%)
\end{itemize}

This reflects the unpredictable nature of phishing techniques.

\section{Methodology}

\subsection{Preprocessing}
\begin{itemize}
    \item Target encoding: labels mapped from \{-1, 1\} to \{0, 1\}
    \item Train-test split: 80/20 stratified
    \item Feature scaling (StandardScaler) for SVM, KNN, Logistic Regression
\end{itemize}

\subsection{Models Implemented}
\begin{enumerate}
    \item Logistic Regression
    \item Support Vector Machine (RBF kernel)
    \item K-Nearest Neighbors
    \item Decision Tree Classifier
    \item Gradient Boosting Classifier
    \item Random Forest (baseline)
\end{enumerate}

\subsection{Hyperparameters}
\begin{itemize}
    \item Random Forest: 100 trees, max depth = None
    \item SVM: C = 1.0, kernel = RBF
    \item KNN: k = 5
    \item Logistic Regression: max\_iter = 200
\end{itemize}

\section{Results}

\subsection{Evaluation Metrics}
Accuracy, Recall, Precision, F1-score and Confusion Matrices were computed for every model.

Example baseline performance (Random Forest):
\begin{itemize}
    \item Accuracy: \textbf{97.5\%}
\end{itemize}

\subsection{Overfitting / Underfitting Analysis}
Random Forest and Gradient Boosting show strong generalisation.  
Decision Trees tend to overfit due to high variance, while Logistic Regression underfits slightly due to linear boundaries.  
SVM performs well but is computationally heavier.

\section{Evaluation and Comparison with Baseline}

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
Model & Accuracy & Recall & F1-score \\
\midrule
Logistic Regression & ... & ... & ... \\
SVM (RBF) & ... & ... & ... \\
KNN (k=5) & ... & ... & ... \\
Decision Tree & ... & ... & ... \\
Gradient Boosting & ... & ... & ... \\
Random Forest (baseline) & 0.975 & ... & ... \\
\bottomrule
\end{tabular}
\caption{Performance Comparison of All Models}
\end{table}

\section{Limitations}
\begin{itemize}
    \item Features are engineered and discrete; they may not capture full URL semantics.
    \item Duplicate conflicts (3.2\%) may add noise.
    \item No deep learning or NLP-based URL embedding was used due to time constraints.
    \item Dataset does not include modern obfuscation techniques (Unicode, punycode).
\end{itemize}

\section{Discussion and Conclusion}
The project successfully demonstrates that classical machine learning models, especially ensemble methods, are highly effective for phishing website detection.

Random Forest and Gradient Boosting achieved the highest performance, with Random Forest reaching 97.5\% accuracy.  
The dataset was well-balanced and clean, requiring minimal preprocessing.  
Future work could include:
\begin{itemize}
    \item Deep learning models (e.g., LSTMs or transformers for URL sequences),
    \item Real-time URL feature extraction,
    \item Augmenting the dataset with modern phishing patterns.
\end{itemize}

\end{document}
